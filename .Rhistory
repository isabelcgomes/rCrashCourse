dados <- data('USArrests')
View(USArrests)
# Detecção de variáveis atípicas: promo calculando a distância (Mahalonobs, euclidiana...)
?dist
# Detecção de variáveis atípicas: promo calculando a distância (Mahalonobs, euclidiana...)
?dist
install.packages('factoextra')
library(factorextra)
library(readxl)
setwd("C:/Users/Isabel Giannecchini/Desktop/SSD/rCrashCourse")
dados <- read_excel('dados\Banco de Dados __SSD 2 2023 (1).xlsx')
dados <- read_excel('dados/Banco de Dados __SSD 2 2023 (1).xlsx')
columns(daddos)
column_names(daddos)
summary(daddos)
summary(dados)
lista_genero <- c(unique(dados$genero))
dados$genero_num <- factor(dados$genero, labels=c(0,1), levels = lista_genero)
lista_genero <- c(unique(dados$Genero))
dados$Genero_num <- factor(dados$Genero, labels=c(0,1), levels = lista_genero)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=c(length(lista_inst)), levels = lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=c([0:length(lista_inst)]), levels = lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=[0:length(lista_inst)], levels = lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=c(0:length(lista_inst)), levels = lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=c(1,2,length(lista_inst)), levels = lista_inst)
lista_inst <- c(unique(dados$Grau_de_Instruçao))
length(lista_inst)
dados$Grau_de_Instruçao_num <- factor(dados$Grau_de_Instruçao, labels=c(3,1,2), levels = lista_inst)
shapiro.test(dados$Grau_de_Instruçao_num)
dados$Genero_num <- as.numeric(dados$Genero_num)
dados$Grau_de_Instruçao_num <- as.numeric(dados$Grau_de_Instruçao_num)
shapiro.test(dados$Grau_de_Instruçao_num)
plot(dados$Grau_de_Instruçao_num)
hplot(dados$Grau_de_Instruçao_num)
shapiro.test(dados$Altura)
# P Valor > NS
# Aceita H0
# A amostra segue a distribuição normal
plot(dados$Altura)
# P Valor > NS
# Aceita H0
# A amostra segue a distribuição normal
boxplot(dados$Altura)
plot(density(dados$Altura))
levene.test(dados$Grau_de_Instruçao_num)
leveneTest(dados$Grau_de_Instruçao_num)
)
library(readxl)
library(dplyr)
library(car)
library(readxl)
library(psych)
leveneTest(dados$Grau_de_Instruçao_num)
leveneTest(dados$Salario ~ dados$Grau_de_Instruçao_num, center=mean)
leveneTest(dados$Salario ~ dados$Grau_de_Instruçao, center=mean)
leveneTest(dados$Salario ~ dados$N_Filhos , center=mean)
leveneTest(dados$Salario ~ dados$Genero, center=mean)
leveneTest(dados$Grau_de_Instruçao_num ~ dados$Genero, center=mean)
leveneTest(dados$N_filhos ~ dados$Genero, center=mean)
leveneTest(dados$N_Filhos ~ dados$Genero, center=mean)
leveneTest(dados$Idade ~ dados$Altura, center=mean)
leveneTest(dados$Idade ~ dados$Genero, center=mean)
leveneTest(dados$Altura ~ dados$Genero, center=mean)
leveneTest(dados$N_Filhos ~ dados$Grau_de_Instruçao, center=mean)
# Teste T
# Avalia se a tendência central de uma amostra está de acordo com o esperado
t.test(dados$Altura, mu = 167)
# Teste T
# Avalia se a tendência central de uma amostra está de acordo com o esperado
t.test(dados$Altura, mu = 168)
# Teste T
# Avalia se a tendência central de uma amostra está de acordo com o esperado
t.test(dados$Altura, mu = 168.5)
# Teste T
# Avalia se a tendência central de uma amostra está de acordo com o esperado
t.test(dados$Altura, mu = 163)
mean(dados$altura)
mean(dados$Altura)
table(dados$Genero)
nclass.Sturges(dados$Salario)
table(cut(dados$Salario, seq(0, n_class, 1=(n_class+1))))
table(cut(dados$Salario, seq(0,6,l=7)))
table(cut(dados$Salario, seq(0, n_class, l=(n_class+1))))
n_class <- nclass.Sturges(dados$Salario)
#divide meu conjunto de dados contínuos em categorias, grupinhos
table(cut(dados$Salario, seq(0, n_class, l=(n_class+1))))
plot(density(table(cut(dados$Salario, seq(0, n_class, l=(n_class+1))))))
summary(dados)
summary(dados)
describe(dados)
describeBy(dados)
describeBy(dados$Salario, group = dados$Genero)
describeBy(dados, group = dados$Genero)
describeBy(dados, group = dados$Genero : dados$Grau_de_Instruçao)
describeBy(dados, group = dados$Genero: dados$Grau_de_Instruçao_num)
describeBy(dados$Salario, group = dados$Genero: dados$Grau_de_Instruçao_num)
describeBy(dados$Salario, group = dados$Genero ~ dados$Grau_de_Instruçao_num)
describeBy(dados, group = dados$Genero)
t.test(dados$Altura, mu = 167, alternative = "greater")
t.test(dados$Altura, mu = 167, alternative = "less")
t.test(dados$Altura, mu = 163, alternative = "greater")
t.test(dados$Altura, mu = 163, alternative = "less")
byf.shapiro(Salario ~ Genero, dados)
library(RVAideMemoire)
byf.shapiro(Salario ~ Genero, dados)
leveneTest(Salario ~ Genero, dados, center=mean)
library(pacman)
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggmisc, psych)
mod <- lm(Salario ~ Genero, dados)
shapiro.test(mod$residuals)
summary(rstandard(mod))
bptest(mod)#breusch-pagan - verifica a homocedasticidade do modelo
#regressão => breusch-pagan
#dados separados => levene (homogeneidade)
durbinWatsonTest(mod) #verifica se os resíduos são ou não independentes
summary(mod)
#hipótese nula: b1=b2=b3=...=bx=0 -> modelo não é significativa
#hipótese alternativa: b1!=b2!=b3!=...!=bx!=0 -> modelo é significativo
#se pvalor < NS -> a minha hipótese alternativa indica que uma determinada variável pode influenciar a outra variável
#meu r² indica o quanto minha variável independente explica minha variável dependente em níveis percentuais
#r² ajustado é o ajuste do meu r² para corrigir algumas questões do modelo
#meu r² maior só é melhor se eu estou avaliando a população inteira
ggplot(data = dados, mapping = aes(x = Genero, y = Salario))+
geom_point()+theme_classic()+
geom_smooth(method = 'lm', col = "red")
bptest(mod)#breusch-pagan - verifica a homocedasticidade do modelo
# Modelo Linear
mod <- lm(Salario ~ Idade, dados)
shapiro.test(mod$residuals)
summary(rstandard(mod))
bptest(mod)#breusch-pagan - verifica a homocedasticidade do modelo
durbinWatsonTest(mod) #verifica se os resíduos são ou não independentes
summary(mod)
ggplot(data = dados, mapping = aes(x = Idade, y = Salario))+
geom_point()+theme_classic()+
geom_smooth(method = 'lm', col = "red")
shapiro.test(mod$residuals)
summary(rstandard(mod))
bptest(mod)
durbinWatsonTest(mod) #verifica se os resíduos são ou não independentes
summary(mod)
mod<-glm(Genero_num ~ N_Filhos + Grau_de_Instruçao_num,
family = binomial(link = 'logit'), data = dados)
dados$Genero_num <- factor(dados$Genero, labels=c(0,1), levels = lista_genero)
dados$Genero_num <- as.numeric(dados$Genero_num)
dados$Genero_num <- factor(dados$Genero, labels=c(0,1), levels = lista_genero)
class(dados$Genero_num) = "Numeric"
dados$Genero_num <- factor(dados$Genero, labels=c(0,1), levels = lista_genero)
mod<-glm(Genero_num ~ N_Filhos + Grau_de_Instruçao_num,
family = binomial(link = 'logit'), data = dados)
plot(mod, which = 5)
summary(stdres(mod))
summary(rstandard(mod))
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggmisc, psych, MASS, DescTools, QuantPsyc)
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggmisc, psych, MASS, DescTools, QUantPsyc)
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggmisc, psych, MASS, DescTools, QuantPsyc)
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggminsc, psych, MASS, DescTools, QuantPsyc)
pacman :: p_load(dplyr, ggplot2, car, rstatix, lmtest, ggpubr, ggpmisc, psych, MASS, DescTools, QuantPsyc)
summary(stdres(mod))
plot(mod, which = 5)
pairs.panels(dados)
pairs.panels(dados[2,4,5])
pairs.panels(dados[2:5])
vif(mod)
mod<-glm(Genero_num ~ N_Filhos + Salario,
family = binomial(link = 'logit'), data = dados)
plot(mod, which = 5)
summary(stdres(mod))
pairs.panels(dados[2:5])
vif(mod)
intlog <- dados$Salario * log(dados$Salario)
dados$intlog <- intlog
modint <- glm(Genero_num ~ N_Filhos + Salario + intlog,
family = binomial(link = 'logit'),
data = dados)
summary(stdres(mod))
plot(mod, which = 5)
vif(mod)
modint <- glm(Genero_num ~ N_Filhos + Salario + intlog,
family = binomial(link = 'logit'),
data = dados)
intlog <- dados$Salario * log(dados$Salario)
dados$intlog <- intlog
modint <- glm(Genero_num ~ N_Filhos + Salario + intlog,
family = binomial(link = 'logit'),
data = dados)
summary(modint)
logito <- mod$linear.predictors
dados$logito <- logito
ggplot(dados, aes(logito, Salario)) +
geom_point(size=0.5, alpha=0.5) +
geom_smooth(method = 'loess') +
theme_classic()
box.tidwell(Genero_num ~ N_Filhos + Salario)
boxTidwell(Genero_num ~ N_Filhos + Salario)
boxTidwell(Genero_num ~ N_Filhos + Salario, data = dados)
boxTidwell(Genero ~ N_Filhos + Salario, data = dados)
boxTidwell(Genero_num ~ N_Filhos + Salario, poly(F, 2), data = dados)
boxTidwell(Genero_num ~ N_Filhos + Salario, poly(F, 1), data = dados)
boxTidwell(Genero_num ~ N_Filhos + Salario, poly(0, 1), data = dados)
boxTidwell(Genero_num ~ N_Filhos + Salario, ~poly(0, 1), data = dados)
boxTidwell(Genero_num ~ N_Filhos + Salario, ~poly(F, 1), data = dados)
ggplot(dados, aes(logito, Salario)) +
geom_point(size=0.5, alpha=0.5) +
geom_smooth(method = 'loess') +
theme_classic()
Anova(mod, type = 'II', test= 'Wald')
exp(cbind(OR = coef(mod), confint(mod)))  #OR = odd ratio (razões de chance)
exp(coef(mod))
exp(cbind(OR = coef(mod), confint.default(mod)))
mod2 <- glm(Genero_num ~ N_Filhos,
family = binomial(link = 'logit'),
data = dados)
Anova(mod2, type = 'II', test= 'Wald')
summary(mod2)
exp(cbind(OR=coef(mod2), confint(mod2)))
PseudoR2(mod, which = 'Nagelkerke')
PseudoR2(mod2, which = 'Nagelkerke')
AIC(mod, mod2)
BIC(mod, mod2)
mod3 <- glm(Genero_num ~ N_Filhos+Altura+Idade,
family = binomial(link = 'logit'),
data = dados)
summary(mod3)
Anova(mod3, type = 'II', test= 'Wald')
exp(cbind(OR=coef(mod3), confint(mod3)))
PseudoR2(mod, which = 'Nagelkerke')
PseudoR2(mod3, which = 'Nagelkerke')
AIC(mod, mod3)
BIC(mod, mod3)
ClassLog(MOD = mod, dados$Genero_num)
ClassLog(mod2, dados$Genero_num)
ClassLog(MOD = mod, dados$Genero_num)
ClassLog(mod3, dados$Genero_num)
table(dados$Genero_num)
table(dados$Genero_num, dados$N_Filhos)
data <- data('USArrests')
fact <- data.frame(factbook[,2:11], row.names = factbook$GROCERY)
p.cov <- data.frame(data)
pmean <- apply(data, 2, mean)
fact <- data.frame(dados, row.names = dados$Salario)
fact <- data.frame(dados, row.names = dados$Grupos)
fact <- data.frame(dados[1:6;8;9], row.names = dados$Salario)
fact <- data.frame(dados[1:6], row.names = dados$Salario)
fact <- data.frame(dados[1:6])
fact <- data.frame(dados)
p.cov <- var(scale(fact))
fact <- data.frame(dados[4:9])
p.cov <- var(scale(fact))
dados$Grau_de_Instruçao_num <- as.numeric(dados$Grau_de_Instruçao_num)
dados$Genero_num <- as.numeric(dados$Genero_num)
p.cov <- var(scale(fact))
dados$Genero_num <- as.numeric(dados$Genero_num)
dados$Grau_de_Instruçao_num <- as.numeric(dados$Grau_de_Instruçao_num)
fact <- data.frame(dados[4:9])
p.cov <- var(scale(fact))
p.cov <- var(fact)
pmean <- apply(fact, 2, mean)
p.mah <- mahalanobis(fact, p.mean, p.cov)
p.mean <- apply(fact, 2, mean)
p.mah <- mahalanobis(fact, p.mean, p.cov)
p.cov <- var(scale(fact))
View(p.cov)
p.cov <- var(fact)
p.cov <- var(scale(fact))
p.mean <- apply(fact, 2, mean)
p.mah <- mahalanobis(fact, p.mean, p.cov)
remover <- c('Altura')
fact.r <- fact[!(row.names(fact) %in% remover),]
fact.p <- scale(fact.r)
View(fact.p)
p.cov <- var(fact)
dados$Genero_num <- as.numeric(dados$Genero_num)
dados$Grau_de_Instruçao_num <- as.numeric(dados$Grau_de_Instruçao_num)
fact <- data.frame(dados[4:9])
p.cov <- var(scale(fact))
p.cov <- var(fact)
p.mean <- apply(fact, 2, mean)
p.mah <- mahalanobis(fact, p.mean, p.cov)
remover <- c('Altura')
fact.r <- fact[!(row.names(fact) %in% remover),]
View(fact.r)
remover <- c('Altura')
fact.r <- fact[!(row.names(fact) %in% remover)]
fact.r <- fact[!(row.names(fact) %in% remover),]
View(fact.r)
fact <- subset(fact, select = -Altura )
View(fact)
dados$Genero_num <- as.numeric(dados$Genero_num)
dados$Grau_de_Instruçao_num <- as.numeric(dados$Grau_de_Instruçao_num)
fact <- data.frame(dados[4:9])
p.cov <- var(scale(fact))
p.cov <- var(fact)
p.mean <- apply(fact, 2, mean)
p.mah <- mahalanobis(fact, p.mean, p.cov)
fact.r <- subset(fact, select = -Altura )
fact.p <- scale(fact.r)
d.eucl <- dist(fact.p, method = 'euclidean')
round(as.matrix(d.eucl)[1:5,1:5],1)
#Método hierárquico da variância mínima de ward ou distância média
# Hierárquico (aglomerativo/divisível)
# Não hierárquico
res.hc <- hclust(d = d.eucl, method = 'ward.D2')
#Matriz cofonética
res.coph <- cophonetic(res.hc)
#Correlação entre a distância cofonética e a distância original
cor(d.eucl, res.coph)
#comparando o método de ligação média - distância média
hc.m <- hclust(d.eucl, method = 'average')
#Correlação entre a distância cofonética (com base no método da ligação média) e a distância original
cor(d.eucl, cophonetic(hc.m))
fviz_dend(hc.m, cex = 0.5)
if(!require(factoextra)) install.packages("factoextra")
if(!require(readxl)) install.packages("readxl")
if(!require(dplyr)) install.packages("dplyr")
if(!require(car)) install.packages("car")
if(!require(psych)) install.packages("psych")
if(!require(RVAideMemoire)) install.packages("RVAideMemoire")
if(!require(pacman)) install.packages("pacman")
library(factorextra)
library(factoextra)
#Correlação entre a distância cofonética (com base no método da ligação média) e a distância original
cor(d.eucl, cophonetic(hc.m))
#Correlação entre a distância cofonética (com base no método da ligação média) e a distância original
cor(d.eucl, cophonetic(hc.m))
fviz_dend(hc.m, cex = 0.5)
#Correlação entre a distância cofonética (com base no método da ligação média) e a distância original
cor(d.eucl, cophenetic(hc.m))
#comparando o método de ligação média - distância média
hc.m <- hclust(d.eucl, method = 'average')
fviz_dend(hc.m, cex = 0.5)
